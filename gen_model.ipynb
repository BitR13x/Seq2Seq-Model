{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from MyDataset import TextDataset\n",
    "from my_tokenizer import tokenizer\n",
    "from model import Seq2SeqModel\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle(\"mydata.pkl\")\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: jedinci sebemenšího 1 kdyby absolvuje silným vagón živého vagón docházka články jedinci problematiku problematiku vagón absolvuje sebemenšího milionářem nabývá 11 jakou 1 ženami 1 nebojíme jedinci verš vagón absolutní jakou 1 ženami junák silným dobra dobra živého 11 11 toho 1 kipling 11 jedinci toho absolvuje přestáváme 1 jakou absolutní jakou jedinci toho 1 ženami jedinci absolutní jedinci 1 ženami vagón silným jedinci absolutní nabývá taková vagón živého 1 ženami 1 ženami jedinci verš taková absolutní jakou 11 absolvuje byl 1 jedinci 11 alfreda absolvuje protějšky toho absolutní absolvuje jím 11 jím sebemenšího nade 11 absolvuje přestáváme 1 nebojíme ideál 11 vagón jedinci toho silným taková 1 jedinci vagón 1 ženami vagón jedinci vagón dnešním absolutní jakou jedinci 11 ideál toho 11 jakou jedinci 1 nebojíme jedinci 11 absolvuje byl 1 alfreda toho absolvuje protějšky absolutní jedinci absolutní absolvuje protějšky 11 absolvuje toho neobvyklého 11 jakou 11 - silným toho toho málo absolutní 11 jedinci toho jedinci absolvuje absolutní sebemenšího všechna 11 jakou 11 prožil absolutní sebemenšího všechna absolutní jedinci 11 jedinci verš vagón 1 proudily toho 1 proudily ideál 11 absolvuje přestáváme nabývá jedinci jedinci absolutní nabývá silným nabývá svěřují sebemenšího nade absolutní jedinci toho toho taková sebemenšího 1 nebojíme 11 alfreda 11 11 absolvuje sebemenšího milionářem absolutní málo 11 prožil 11 jím sebemenšího toho 1 absolvuje toho toho 1 který ideál absolutní prožil absolvuje sebemenšího všechna jedinci verš vagón 11 vagón docházka jedinci 1 cosi byl ideál absolvuje sebemenšího nabývá vagón 11 vagón silným absolutní jedinci absolvuje jedinci ideál jedinci ideál 1 kipling sebemenšího milionářem absolvuje jím 1 absolvuje jedinci nápadnou absolutní nabývá toho 1 proudily toho sebemenšího absolutní cosi byl 1 alfreda ideál sebemenšího jedinci 1 cosi sebemenšího všechna vagón ideál jedinci verš 11 11 antonína jedinci ideál 1 nebojíme toho taková jedinci 11 jakou absolutní jedinci\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = TextDataset(data, tokenizer, max_length)\n",
    "\n",
    "special_tokens = {\"CLS\": 3, \"eos\": 2, \"pad\": 1, \"unk\": 0}\n",
    "dataset.tokenizer.stoi.update(special_tokens)\n",
    "n_words = dataset.get_vocab_len()\n",
    "\n",
    "model = Seq2SeqModel(vocab_size=n_words, embed_size=128, hidden_size=256, num_layers=1)\n",
    "model.load_state_dict(torch.load('GPT_model.pth', weights_only=True))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "def apply_temperature(logits, temperature=0.5):\n",
    "    logits = logits / temperature\n",
    "    return torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "def top_k_sampling(logits, k=10):\n",
    "    # Take the logits from the model output and apply top-k sampling\n",
    "    top_k_values, top_k_indices = torch.topk(logits, k)\n",
    "    top_k_probs = torch.nn.functional.softmax(top_k_values, dim=-1)\n",
    "    sampled_token = torch.multinomial(top_k_probs, 1)\n",
    "    return top_k_indices[0, sampled_token]\n",
    "\n",
    "def generate_text(model, title, tokenizer, max_len=300):\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare title input\n",
    "    title_tokens = tokenizer(title)\n",
    "    title_tokens = torch.tensor([dataset.tokenizer.stoi[token] for token in title_tokens]).long()\n",
    "    title_tokens = torch.nn.functional.pad(title_tokens, (0, 256 - title_tokens.shape[0] - 1), value=special_tokens[\"pad\"])\n",
    "    title_tokens = torch.nn.functional.pad(title_tokens, (0, 1), value=special_tokens[\"eos\"])\n",
    "\n",
    "\n",
    "    generated_text = []\n",
    "    input_text = torch.tensor([[special_tokens[\"CLS\"]]]).long().to(device)  # Starting input token\n",
    "\n",
    "    title_tokens = title_tokens.unsqueeze(0).to(device)\n",
    "    for _ in range(max_len):\n",
    "        output = model(title_tokens, input_text)\n",
    "        #next_token = torch.argmax(output[:, -1, :])\n",
    "        #generated_text.append(next_token.item())\n",
    "        \n",
    "        # Get logits for the last token in the sequence\n",
    "        logits = output[:, -1, :]\n",
    "\n",
    "        logits = apply_temperature(logits)\n",
    "        sampled_token = top_k_sampling(logits)\n",
    "        generated_text.append(sampled_token.item())\n",
    "\n",
    "\n",
    "        # Stop if <eos> token is generated\n",
    "        if sampled_token == special_tokens[\"eos\"]:\n",
    "            break\n",
    "\n",
    "        # Prepare next input\n",
    "        input_text = torch.cat([input_text, torch.tensor([[sampled_token.item()]])], dim=1)\n",
    "\n",
    "\n",
    "    decoded_text = \"\"\n",
    "    keys = list(dataset.tokenizer.stoi.keys())\n",
    "    for idx in generated_text:\n",
    "        if idx <= len(dataset.tokenizer.stoi):\n",
    "            decoded_text += \" \" + keys[idx]\n",
    "        else:\n",
    "            decoded_text += \" <unk>\"\n",
    "\n",
    "    return decoded_text.strip()\n",
    "\n",
    "# Example usage\n",
    "title = \"Věřím?\"\n",
    "generated_text = generate_text(model, title, tokenizer)\n",
    "print(\"TEXT:\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
